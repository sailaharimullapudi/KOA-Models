{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8326b135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf6e8cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df length:  5778   test_df length:  1656   valid_df length:  826\n",
      "The number of classes in the dataset is:  5\n",
      "            CLASS               IMAGE COUNT \n",
      "           Doubtful                1046     \n",
      "           Healthy                 2286     \n",
      "           Minimal                 1516     \n",
      "           Moderate                 757     \n",
      "            Severe                  173     \n"
     ]
    }
   ],
   "source": [
    "train_path = \"/Users/sailaharimullapudi/Desktop/kneeKL224/train\"\n",
    "test_path = \"/Users/sailaharimullapudi/Desktop/kneeKL224/test\"\n",
    "valid_path = \"/Users/sailaharimullapudi/Desktop/kneeKL224/val\"\n",
    "list_of_classes = ['Healthy', 'Doubtful', 'Minimal', 'Moderate', 'Severe']\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "for d in [train_path, test_path, valid_path]:\n",
    "    filepaths = []\n",
    "    labels = [] \n",
    "    classlist = os.listdir(d)\n",
    "    \n",
    "    for klass in classlist:\n",
    "        try:\n",
    "            intklass = int(klass)\n",
    "            label = list_of_classes[intklass]\n",
    "            classpath = os.path.join(d, klass)\n",
    "            flist = os.listdir(classpath)        \n",
    "            \n",
    "            for f in flist:\n",
    "                fpath = os.path.join(classpath, f)\n",
    "                filepaths.append(fpath)\n",
    "                labels.append(label)\n",
    "        \n",
    "        except ValueError:\n",
    "            # Skip directories that are not valid integers\n",
    "            continue\n",
    "    \n",
    "    Fseries = pd.Series(filepaths, name='filepaths')\n",
    "    Lseries = pd.Series(labels, name='labels')        \n",
    "    pdf = pd.concat([Fseries, Lseries], axis=1)\n",
    "    \n",
    "    if d == test_path:\n",
    "        test_df = pdf\n",
    "    elif d == valid_path:\n",
    "        valid_df = pdf\n",
    "    else:\n",
    "        train_df = pdf\n",
    "\n",
    "print('train_df length: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))\n",
    "\n",
    "# get the number of classes and the images count for each class in train_df\n",
    "classes = sorted(list(train_df['labels'].unique()))\n",
    "class_count = len(classes)\n",
    "print('The number of classes in the dataset is: ', class_count)\n",
    "groups = train_df.groupby('labels')\n",
    "print('{0:^30s} {1:^13s}'.format('CLASS', 'IMAGE COUNT'))\n",
    "countlist = []\n",
    "classlist = []\n",
    "for label in sorted(list(train_df['labels'].unique())):\n",
    "    group = groups.get_group(label)\n",
    "    countlist.append(len(group))\n",
    "    classlist.append(label)\n",
    "    print('{0:^30s} {1:^13s}'.format(label, str(len(group))))\n",
    "\n",
    "# lets get the average height and width of a sample of the train images\n",
    "ht = 0\n",
    "wt = 0\n",
    "\n",
    "train_df_sample = train_df.sample(n = 100, random_state = 123, axis = 0)\n",
    "for i in range (len(train_df_sample)):\n",
    "    fpath = train_df_sample['filepaths'].iloc[i]\n",
    "    img = plt.imread(fpath)\n",
    "    shape = img.shape\n",
    "    ht += shape[0]\n",
    "    wt += shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9df64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes in the dataset is:  5\n",
      "            CLASS               IMAGE COUNT \n",
      "           Doubtful                 296     \n",
      "           Healthy                  639     \n",
      "           Minimal                  447     \n",
      "           Moderate                 223     \n",
      "            Severe                  51      \n"
     ]
    }
   ],
   "source": [
    "classes = sorted(list(test_df['labels'].unique()))\n",
    "class_count = len(classes)\n",
    "print('The number of classes in the dataset is: ', class_count)\n",
    "groups = test_df.groupby('labels')\n",
    "print('{0:^30s} {1:^13s}'.format('CLASS', 'IMAGE COUNT'))\n",
    "countlist = []\n",
    "classlist = []\n",
    "for label in sorted(list(test_df['labels'].unique())):\n",
    "    group = groups.get_group(label)\n",
    "    countlist.append(len(group))\n",
    "    classlist.append(label)\n",
    "    print('{0:^30s} {1:^13s}'.format(label, str(len(group))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dded5227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size - avg hight and width\n",
    "average_height = ht // 100\n",
    "average_width = wt // 100\n",
    "image_size = (average_height, average_width)\n",
    "\n",
    "# preprocess images\n",
    "def preprocess(filepaths):\n",
    "    images = []\n",
    "    for filepath in filepaths:\n",
    "        img = plt.imread(filepath)\n",
    "        img = resize(img, image_size, anti_aliasing=True)\n",
    "        img_flat = img.flatten()\n",
    "        images.append(img_flat)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c6da253",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = preprocess(train_df['filepaths'])\n",
    "test_images = preprocess(test_df['filepaths'])\n",
    "valid_images = preprocess(valid_df['filepaths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "851cb894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# label encoding \n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_df['labels'])\n",
    "test_labels = label_encoder.transform(test_df['labels'])\n",
    "valid_labels = label_encoder.transform(valid_df['labels'])\n",
    "\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83135020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "all_data_labels = np.concatenate([train_labels, valid_labels])\n",
    "all_data_images = np.concatenate([train_images, valid_images])\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "svm = SVC(kernel = 'linear', probability = True, decision_function_shape = 'ovr', C = 1.0)\n",
    "\n",
    "cross_val = cross_val_score(svm, all_data_images, all_data_labels, cv = kfold, scoring = 'accuracy')\n",
    "\n",
    "svm.fit(all_data_images, all_data_labels)\n",
    "\n",
    "test_predictions = svm.predict(test_images)\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "report = classification_report(test_labels, test_predictions, target_names=list_of_classes)\n",
    "\n",
    "print(f\"Cross-Validation Accuracy: {np.mean(cross_val)}\")\n",
    "print(f\"Test Set Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ae600",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(test_labels, test_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matrix, annot=True, cmap = \"Blues\", fmt=\"d\", cbar=False,\n",
    "            xticklabels=list_of_classes, yticklabels=list_of_classes)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f05f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_function = svm.decision_function(test_images)\n",
    "train_labels_binary = label_binarize(test_labels, classes=np.unique(train_labels))\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(np.unique(train_labels))):\n",
    "    fpr[i], tpr[i], _ = roc_curve(train_labels_binary[:, i], decision_function[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(np.unique(train_labels))):\n",
    "    x = \"\"\n",
    "    if i == 0:\n",
    "        x = \"Healthy\"\n",
    "    elif i == 1:\n",
    "        x = \"Doubtful\"\n",
    "    elif i == 2:\n",
    "        x = \"Minimal\"\n",
    "    elif i == 3:\n",
    "        x = \"Moderate\"\n",
    "    else:\n",
    "        x = \"Severe\"\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label='ROC Curve: Class {} (AUC = {:.2f})'.format(x, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Each Class (Support Vector Machine)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6149b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix_heatmap(data, class_names, title, xlabel, ylabel):\n",
    "    df_cm = pd.DataFrame(data, index=[xlabel], columns=class_names)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(df_cm, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "sensitivity = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "specificity = np.diagonal(conf_matrix[::-1, ::-1]) / conf_matrix[::-1, ::-1].sum(axis=1)\n",
    "\n",
    "sensitivity_heatmap = np.array([sensitivity])\n",
    "specificity_heatmap = np.array([specificity])\n",
    "\n",
    "plot_confusion_matrix_heatmap(sensitivity_heatmap, list_of_classes, title='Sensitivity', xlabel='', ylabel='Sensitivity')\n",
    "\n",
    "plot_confusion_matrix_heatmap(specificity_heatmap, list_of_classes, title='Specificity', xlabel='', ylabel='Specificity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6dde30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
